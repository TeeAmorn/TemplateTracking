# Implementation Overview
My implementation can be split into two general steps: performing exhaustive search locally and matching each candidate in the searching window with the template. These two steps are performed iteratively until all frames have been processed. The next few paragraphs will elaborate on each of these two steps.

Exhaustive search is performed by iterating through every possible candidate inside the searching window. Any region of the image that is the searching window and has the same size as the template is a possible candidate. The window and template sizes I have chosen for this task are 53\times53 and 43\times43 pixels respectively. For each candidate, a matching score is computed; this process will be further explained in the next paragraph. After the score of every possible within the searching window is computed, the candidate with the highest score is considered as the new tracked image. This tracked image will also be used as the template for the next frame of our video. 

The matching process is relatively simple. For any given candidate and template, we have three choices with regards to how we wish to score how well the two matches. The three methods we can use to assess how well they match are sum of squared differences, cross-correlation, and normalized cross-correlation. 

The first method, sum of squared differences, is self-explanatory: it computes the difference between each pair of pixels in the two images and then square the difference. The total cost will be the sum of the squared differences. Since we wish to reward lower cost, I have set the score for this matching method to be the inverse of the cost. 

The other two methods, cross-correlation and normalized cross-correlation are merely dot products of the two images. If the two images are identical, then we can expect a large dot product. If they are completely different (analogous to two perpendicular lines), then their dot product would be 0. The latter method simply standardizes each image before it is compared. The dot product is used as the score for both methods.

 Based on the submitted videos for each of the three methods, we can see that the cross-correlation method (without normalization) performed the worst. The tracking box appears to jitter a lot, appearing to “vibrate” about the woman’s face initially before quickly losing the ability to track her face accurately. The sum of squared differences appeared to perform significantly better than the cross-correlation method, but not as well as the normalized cross-correlation method. 

Generally, the three methods were able to track the woman’s face initially. However, the tracking became increasingly inaccurate as she began to turn. We first see the box starting to deviate away from the woman’s face around the 100th frame, when she has turned away from the camera. By the time she faced the camera again on the 130th frame, only half the woman’s face is inside the box. Around the 300th frame, when the woman leans to the right, she becomes almost completely outside the box. Nevertheless, the box is able to follow the woman’s general direction. When a man’s face came inside the box around the 420th frame, the box began tracking his face as he moved down. The box eventually tracks back onto the woman’s face again around the 450th frame as the man moves out of the frame.  
